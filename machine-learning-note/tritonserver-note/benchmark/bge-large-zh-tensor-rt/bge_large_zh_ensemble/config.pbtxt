
name: "bge_large_zh_ensemble"
platform: "ensemble"
max_batch_size: 32

input [
  {
    name: "ensemble_input"
    data_type: TYPE_STRING
    dims: [1]
  }
]
output [
  {
    name: "ensemble_dense_vecs"
    data_type: TYPE_FP32
    dims: [1024]
  },
  {
    name: "ensemble_dense_token_num"
    data_type: TYPE_UINT32
    dims: [1]
  }
]

ensemble_scheduling {
  step [
    {
      model_name: "python_bge_large_zh_tokenizer"
      model_version: -1
      input_map {
        key: "input"
        value: "ensemble_input"
      },
      output_map {
        key: "input_ids"
        value: "tokenizer_input_ids"
      },
      output_map {
        key: "attention_mask"
        value: "tokenizer_attention_mask"
      },
      output_map {
        key: "token_num"
        value: "ensemble_dense_token_num"
      }
    },
    {
      model_name: "bge_large_zh_trt"
      model_version: -1
      input_map {
        key: "input_ids"
        value: "tokenizer_input_ids"
      },
      input_map {
        key: "attention_mask"
        value: "tokenizer_attention_mask"
      },
      output_map {
        key: "sentence_embedding"
        value: "ensemble_dense_vecs"
      }
    }
  ]
}

parameters: {
  key: "FORCE_CPU_ONLY_INPUT_TENSORS"
  value:{string_value:"no"}
}
